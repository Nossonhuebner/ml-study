{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53acf757-1c62-40e3-a686-6836cbf23f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c7859-9af4-4cd0-8636-046daa573f84",
   "metadata": {},
   "source": [
    "#### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa6f669-a61e-4c4b-83d3-b4a3e0ea514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment if not downloaded previously\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fed39-0fe3-4e8c-a008-82491d3b69f3",
   "metadata": {},
   "source": [
    "#### format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091ca878-da9f-4839-afda-d842c58c0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "all_letters = string.ascii_letters + \" .,;'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d812f13-2aab-4795-8ec8-a9a3dbd1d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "import unicodedata\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ba7727-3a89-48b9-9f79-2118a98e5166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Korean, Irish, Portuguese, Vietnamese, Czech, Russian, Scottish, German, Polish, Spanish, English, French, Japanese, Dutch, Greek, Chinese, Italian, Arabic'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "category_lines = {}\n",
    "categories = []\n",
    "path = '02-data/names/'\n",
    "for fname in os.listdir(path):\n",
    "    lang = fname.split('.')[0]\n",
    "    categories.append(lang)\n",
    "    category_lines[lang] = []\n",
    "    with open(path+fname, 'r') as f:\n",
    "      for line in f:\n",
    "        category_lines[lang].append(unicodeToAscii(line.strip()))\n",
    "', '.join(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae71ef9-40f1-4475-a7be-cfd03062b4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean',\n",
       " 'Irish',\n",
       " 'Portuguese',\n",
       " 'Vietnamese',\n",
       " 'Czech',\n",
       " 'Russian',\n",
       " 'Scottish',\n",
       " 'German',\n",
       " 'Polish',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'French',\n",
       " 'Japanese',\n",
       " 'Dutch',\n",
       " 'Greek',\n",
       " 'Chinese',\n",
       " 'Italian',\n",
       " 'Arabic']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be82e438-d2f5-4c55-8e08-3e32366f0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4757710-4537-490d-b3d7-7af06d602860",
   "metadata": {},
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bfe9a2-c3ab-4247-a499-07dff996c9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_letters = len(all_letters);num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de80198b-d3d1-4b67-902d-375cd0aba18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "letterToIndex('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af3020a-5681-4b18-8fad-1e05e8c20455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_one_hot(char):\n",
    "    zeros = torch.zeros(1, num_letters)\n",
    "    zeros[0][letterToIndex(char)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b154a6-b855-49a1-aaa8-c7585228b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_one_hot('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36bc508-3906-4372-9912-e9d5ada20454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_onehot(word):\n",
    "    zeros = torch.zeros(len(word), 1, num_letters)\n",
    "    for i, ch in enumerate(word):\n",
    "        zeros[i][0][letterToIndex(ch)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901c1154-e81a-422d-977c-f6d24414dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]),\n",
       " torch.Size([3, 1, 57]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_onehot('nan'), seq_onehot('nan').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c4c08-5938-4ca9-b592-95ace60404c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8017cb4b-1c96-48ad-803a-d9731ebaa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_and_hidden_to_next_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.new_hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden):\n",
    "        next_hidden = self.input_and_hidden_to_next_hidden(torch.cat((input_tensor, hidden), 1))\n",
    "        output = self.new_hidden_to_output(next_hidden)\n",
    "\n",
    "        return F.log_softmax(output, dim=1), next_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91ee6a30-f63d-4988-94f7-97071c7fa28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(num_letters, 50, len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "563f69fa-c2f9-4833-b196-1e67cd61c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.rand((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "529a273c-1296-4cde-bc77-c48ff340bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8482, -2.9735, -3.0370, -2.8171, -3.2030, -3.0298, -2.8035, -2.9455,\n",
      "         -3.1980, -2.8140, -3.1805, -2.6500, -3.0575, -2.9277, -2.4932, -2.4603,\n",
      "         -2.8385, -3.1965]], grad_fn=<LogSoftmaxBackward0>) tensor([[-0.5016,  0.1422, -0.0884,  0.0171, -0.1455, -0.0130, -0.0572,  0.2246,\n",
      "          0.5929,  0.1226,  0.2759, -0.1772,  0.3595,  0.0986,  0.1152,  0.1045,\n",
      "         -0.2089, -0.2540, -0.2240, -0.4257, -0.0678,  0.3477,  0.1459, -0.1279,\n",
      "          0.3287,  0.1390,  0.2207,  0.3165,  0.0074, -0.0308, -0.0623, -0.0495,\n",
      "          0.1834,  0.0832, -0.3110,  0.2726,  0.4092,  0.0866, -0.1679, -0.4909,\n",
      "          0.2964, -0.1197, -0.0023, -0.5089,  0.3814,  0.2589, -0.0415,  0.1600,\n",
      "          0.3638,  0.1026]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8722, -3.0085, -2.9137, -2.7321, -3.0278, -2.9501, -2.8081, -2.8734,\n",
      "         -3.1450, -2.8087, -3.0212, -2.8265, -3.1134, -2.8665, -2.6831, -2.6646,\n",
      "         -2.8621, -3.0091]], grad_fn=<LogSoftmaxBackward0>) tensor([[-0.2979,  0.1187, -0.1629, -0.0523, -0.0896,  0.0395, -0.0297,  0.1636,\n",
      "          0.1113,  0.0432,  0.0570, -0.0492,  0.3304,  0.1282,  0.1827,  0.0795,\n",
      "         -0.0927,  0.0719,  0.1308, -0.1277,  0.0913,  0.0679,  0.2517,  0.1175,\n",
      "          0.0884, -0.0876, -0.0171, -0.0653,  0.0469,  0.1782, -0.0994,  0.0015,\n",
      "          0.0930,  0.0645, -0.0943, -0.0022, -0.0588, -0.0084, -0.0820, -0.0221,\n",
      "          0.1429,  0.0216, -0.1637, -0.1296,  0.0879,  0.0217, -0.0875, -0.1429,\n",
      "          0.1551,  0.1046]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9492, -3.0371, -3.0062, -2.8427, -3.0212, -2.9460, -2.8651, -2.8523,\n",
      "         -3.0829, -2.7912, -3.0147, -2.7722, -2.9847, -2.7199, -2.7233, -2.7213,\n",
      "         -2.9031, -2.9109]], grad_fn=<LogSoftmaxBackward0>) tensor([[-0.2373,  0.1287,  0.0911,  0.0022, -0.0453, -0.0564,  0.0767,  0.0573,\n",
      "          0.0704,  0.0472,  0.0906, -0.1523,  0.1282, -0.0088,  0.1351,  0.0474,\n",
      "         -0.1351,  0.0938,  0.0617, -0.0658,  0.0690, -0.0913,  0.0729, -0.0207,\n",
      "         -0.0053,  0.1104, -0.0116,  0.0195, -0.0503, -0.1196,  0.0608, -0.1235,\n",
      "          0.0440, -0.0095, -0.0362,  0.0151, -0.0336,  0.1006, -0.0216, -0.1653,\n",
      "          0.1305,  0.0708, -0.1013, -0.1457,  0.0681, -0.0779,  0.0484,  0.0568,\n",
      "          0.1638, -0.0164]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for char in seq_onehot('nan'):\n",
    "    output, hidden = rnn(char, hidden)\n",
    "    print(output, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc4f55d8-51c2-4a47-86f7-79dc660e21a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 107])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((seq_onehot('nan')[0], hidden), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "020587ec-9056-41df-b6ea-ffe8ab972f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a5927-2c4a-4ac8-9ce8-2313342a47ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a77a09bb-b7e5-4f60-81fa-93e02935511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_sample():\n",
    "    def rand(collection):\n",
    "        rand_int = random.randint(0, len(collection)-1)\n",
    "        return collection[rand_int]\n",
    "    cat = rand(categories)\n",
    "    item = rand(category_lines[cat])\n",
    "    cat_tensor = torch.tensor([categories.index(cat)])\n",
    "    item_tensor = seq_onehot(item)\n",
    "    return cat, item, cat_tensor, item_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b7c2a11-cb28-4b9a-992e-6ce329065662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('French',\n",
       " 'Bonfils',\n",
       " tensor([11]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2ead14f-5d35-4456-8d68-4fa90e3edc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, item, cten, itens = get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb1a327c-3610-427f-b5a3-2d2da7ca57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in itens:\n",
    "    out, hidden = rnn(ch, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bfabf31f-bcb9-4768-8636-936872e4ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.7200, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][torch.argmax(out).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66f93303-7f59-4c05-8571-5a09d6e41c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(out[0][torch.argmax(out).item()], cten.float()).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8384118-90d2-446c-9f01-2f77af460f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.rand((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "773f4d7b-fc04-44e4-abb8-4a94390bb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85d51620-e0c7-4681-824a-00c4da573667",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m rnn(ch, hidden)\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out[\u001b[38;5;241m0\u001b[39m][torch\u001b[38;5;241m.\u001b[39margmax(out)\u001b[38;5;241m.\u001b[39mitem()], cten\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m----> 8\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m hidden\u001b[38;5;241m.\u001b[39mdetach_()\n\u001b[1;32m     10\u001b[0m out\u001b[38;5;241m.\u001b[39mdetach_()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    cat, item, cten, itens = get_random_sample()\n",
    "\n",
    "    for ch in itens:\n",
    "        out, hidden = rnn(ch, hidden)\n",
    "    \n",
    "    loss = loss_fn(out[0][torch.argmax(out).item()], cten.float())\n",
    "    loss.backward()\n",
    "    hidden.detach_()\n",
    "    out.detach_()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%0 == 0:\n",
    "        print(f'Loss: {loss}')\n",
    "        print(out[0][torch.argmax(out).item()] == cten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb45fa-ea4c-44db-a9e7-7edf3ebca70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87ab1d0e-63ef-461f-924e-ee98a127c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method zero_ of Tensor object at 0x7fb5a021a5e0>\n"
     ]
    }
   ],
   "source": [
    "for gg in rnn.parameters():\n",
    "    print(gg.grad.zero_())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd89d6-bbf2-47d8-96b8-672b2eea72e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
