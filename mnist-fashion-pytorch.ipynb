{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6a35b5d-432b-4c12-86c2-66b1a5695d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b0dc320-58a6-40ee-bc9f-d2ea71b8d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='data', train=False, transform=ToTensor(), download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204f8fe-8e70-49d1-a33e-8e5e98e5eb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5d534b82-9adf-4a50-bafa-adc9060953d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0\n",
      "X shape: torch.Size([1, 28, 28])\n",
      "y shape: 9\n",
      "sample:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 7\n",
    "for batch, (X, y) in enumerate(train_dataset):\n",
    "    print(f'batch number: {batch}')\n",
    "    print(f'X shape: {X.shape}')\n",
    "    print(f'y shape: {y}')\n",
    "    print(f'sample:  {y}')\n",
    "    ToPILImage()(X).show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3185c686-3bc3-4521-89a0-e85e27bc406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d8f379f2-8bfd-4b58-bf4c-b9972b3d3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([x[1] for x in train_dataset]) # list(range(10)) categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f196f7-4e6d-4c9c-8110-eb997a80f48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7321a4a-ff3c-41ce-9d3e-a6540cc6294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NossonBasic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28*28, 1026), nn.ReLU(),\n",
    "            nn.Linear(1026, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad51ea79-cc10-4889-800b-7de6180cdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NossonBasic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a14c468f-8fca-4e91-b80d-0ee2027c8df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0813, -0.1017, -0.0839,  0.0165, -0.0386,  0.0556,  0.0039,  0.0214,\n",
       "          0.0695, -0.1141]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.forward(train_dataset[0][0]) # random output logits for given model params at any point (currently randomly initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db9d94-765d-41f9-b4d4-2ead05109cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19b5d772-2db3-49a4-b002-42c6a868deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c516d7f6-fea0-487f-9165-2add83ba36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(n.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00770528-971e-412b-9026-74dca16ae2cb",
   "metadata": {},
   "source": [
    "#### Inspecting params / grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ee0e8858-ce86-4ea0-956e-09274cebec09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f58855-6fc8-49c6-8e22-8db8cd292da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "edf02d57-4381-4a80-a39a-f40dc7f0d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(n.layers[0].parameters())[1].grad # unset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d64eabf-21dc-49f7-b315-39c47e4327c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.layers[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8d2c1556-8066-4dab-aef0-5b558e5c601a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([-0.0067,  0.0337, -0.0171,  ...,  0.0152,  0.0141, -0.0313],\n",
       "        requires_grad=True),\n",
       " torch.Size([1026]),\n",
       " torch.Size([1026, 784]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[0].bias, n.layers[0].bias.shape, n.layers[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a9953825-a33e-4f97-94bb-7251a3e9ec05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ReLU(), torch.Size([256, 1026]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.layers[1], n.layers[2].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d5a65f89-8681-49b0-93fe-72c0d2ad9489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3934, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss for a single item:\n",
    "l = loss_fn(n.forward(train_dataset[0][0]), torch.tensor(train_dataset[0][1]).unsqueeze(dim=0)); l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "646182b3-c76d-4971-b97a-bd7ae7c1823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0059,  0.0141,  0.0016,  ..., -0.0158,  0.0000,  0.0063])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.backward() # calculate grads through computational graph\n",
    "n.layers[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0b883f4e-db98-4d4d-8ba2-05c946ba2b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0067,  0.0337, -0.0171,  ...,  0.0152,  0.0141, -0.0313],\n",
       "        grad_fn=<CloneBackward0>),\n",
       " Parameter containing:\n",
       " tensor([-0.0057,  0.0327, -0.0181,  ...,  0.0162,  0.0141, -0.0323],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_update_bias = n.layers[0].bias.clone();pre_update_bias # unchanged - for comparison below\n",
    "\n",
    "optimizer.step() # use Adam optimizer to determine param update step\n",
    "\n",
    "new_bias = n.layers[0].bias # updated bias param for layer 0\n",
    "\n",
    "pre_update_bias, new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c661d81-9e4d-4415-a905-6ab7421d2146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad() # reset grads\n",
    "n.layers[0].bias.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
