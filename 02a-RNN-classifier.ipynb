{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53acf757-1c62-40e3-a686-6836cbf23f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c7859-9af4-4cd0-8636-046daa573f84",
   "metadata": {},
   "source": [
    "#### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa6f669-a61e-4c4b-83d3-b4a3e0ea514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment if not downloaded previously\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fed39-0fe3-4e8c-a008-82491d3b69f3",
   "metadata": {},
   "source": [
    "#### format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091ca878-da9f-4839-afda-d842c58c0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "all_letters = string.ascii_letters + \" .,;'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d812f13-2aab-4795-8ec8-a9a3dbd1d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "import unicodedata\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ba7727-3a89-48b9-9f79-2118a98e5166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Korean, Irish, Portuguese, Vietnamese, Czech, Russian, Scottish, German, Polish, Spanish, English, French, Japanese, Dutch, Greek, Chinese, Italian, Arabic'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "category_lines = {}\n",
    "categories = []\n",
    "path = '02-data/names/'\n",
    "for fname in os.listdir(path):\n",
    "    lang = fname.split('.')[0]\n",
    "    categories.append(lang)\n",
    "    category_lines[lang] = []\n",
    "    with open(path+fname, 'r') as f:\n",
    "      for line in f:\n",
    "        category_lines[lang].append(unicodeToAscii(line.strip()))\n",
    "', '.join(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dae71ef9-40f1-4475-a7be-cfd03062b4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean',\n",
       " 'Irish',\n",
       " 'Portuguese',\n",
       " 'Vietnamese',\n",
       " 'Czech',\n",
       " 'Russian',\n",
       " 'Scottish',\n",
       " 'German',\n",
       " 'Polish',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'French',\n",
       " 'Japanese',\n",
       " 'Dutch',\n",
       " 'Greek',\n",
       " 'Chinese',\n",
       " 'Italian',\n",
       " 'Arabic']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be82e438-d2f5-4c55-8e08-3e32366f0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4757710-4537-490d-b3d7-7af06d602860",
   "metadata": {},
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9bfe9a2-c3ab-4247-a499-07dff996c9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_letters = len(all_letters);num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de80198b-d3d1-4b67-902d-375cd0aba18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "letterToIndex('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5af3020a-5681-4b18-8fad-1e05e8c20455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_one_hot(char):\n",
    "    zeros = torch.zeros(1, num_letters)\n",
    "    zeros[0][letterToIndex(char)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91b154a6-b855-49a1-aaa8-c7585228b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_one_hot('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b36bc508-3906-4372-9912-e9d5ada20454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_onehot(word):\n",
    "    zeros = torch.zeros(len(word), 1, num_letters)\n",
    "    for i, ch in enumerate(word):\n",
    "        zeros[i][0][letterToIndex(ch)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "901c1154-e81a-422d-977c-f6d24414dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]),\n",
       " torch.Size([3, 1, 57]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_onehot('nan'), seq_onehot('nan').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc7c4c08-5938-4ca9-b592-95ace60404c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "print(seq_onehot('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8017cb4b-1c96-48ad-803a-d9731ebaa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_and_hidden_to_next_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.new_hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden):\n",
    "        next_hidden = self.input_and_hidden_to_next_hidden(torch.cat((input_tensor, hidden), 1))\n",
    "        output = self.new_hidden_to_output(next_hidden)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "\n",
    "        return output, next_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91ee6a30-f63d-4988-94f7-97071c7fa28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(num_letters, 50, len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "563f69fa-c2f9-4833-b196-1e67cd61c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "529a273c-1296-4cde-bc77-c48ff340bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18])\n"
     ]
    }
   ],
   "source": [
    "for char in seq_onehot('nan'):\n",
    "    output, hidden = rnn(char, hidden)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303c4ee6-8e5b-4a1d-ac35-e48d823bf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed98136-e472-461d-a800-9680001dd69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Greek', 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoryFromOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc4f55d8-51c2-4a47-86f7-79dc660e21a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 107])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((seq_onehot('nan')[0], hidden), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "020587ec-9056-41df-b6ea-ffe8ab972f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a5927-2c4a-4ac8-9ce8-2313342a47ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a77a09bb-b7e5-4f60-81fa-93e02935511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_sample():\n",
    "    def rand(collection):\n",
    "        rand_int = random.randint(0, len(collection)-1)\n",
    "        return collection[rand_int]\n",
    "    cat = rand(categories)\n",
    "    item = rand(category_lines[cat])\n",
    "    cat_tensor = torch.tensor([categories.index(cat)])\n",
    "    item_tensor = seq_onehot(item)\n",
    "    return cat, item, cat_tensor, item_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b7c2a11-cb28-4b9a-992e-6ce329065662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vietnamese',\n",
       " 'Mai',\n",
       " tensor([3]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2ead14f-5d35-4456-8d68-4fa90e3edc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, item, cten, itens = get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb1a327c-3610-427f-b5a3-2d2da7ca57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in itens:\n",
    "    out, hidden = rnn(ch, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfabf31f-bcb9-4768-8636-936872e4ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.6402, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][torch.argmax(out).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66f93303-7f59-4c05-8571-5a09d6e41c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn(out[0][torch.argmax(out).item()], cten.float()).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8384118-90d2-446c-9f01-2f77af460f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f4d7b-fc04-44e4-abb8-4a94390bb21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60ca5518-b786-44a1-8a0c-ac651960807e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0091, -0.0891,  0.0167, -0.1053,  0.0541,  0.0241,  0.1082,  0.0874,\n",
       "          0.0062, -0.1450,  0.1753, -0.0888,  0.0708,  0.0205, -0.0243,  0.1996,\n",
       "         -0.1346, -0.0241, -0.0224, -0.0857,  0.0518, -0.0554,  0.0642,  0.1156,\n",
       "         -0.0324, -0.0037, -0.0876,  0.1573,  0.1526,  0.0521,  0.1785, -0.0898,\n",
       "          0.0717, -0.0123, -0.1349,  0.0199, -0.1606,  0.0172, -0.1679,  0.0666,\n",
       "         -0.1905, -0.1292, -0.1296, -0.0537,  0.1229,  0.1395,  0.0612, -0.0770,\n",
       "          0.1526, -0.0916]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85d51620-e0c7-4681-824a-00c4da573667",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50\n",
    "rnn = RNN(num_letters, n_hidden, len(categories))\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(input_tensor, cat_tensor):\n",
    "    hidden = torch.zeros((1, n_hidden))\n",
    "\n",
    "    for ch in input_tensor:\n",
    "        out, hidden = rnn(ch, hidden)\n",
    "    \n",
    "    loss = loss_fn(out, cat_tensor)\n",
    "    # # hidden.detach_()\n",
    "    # # out.detach_()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96fb45fa-ea4c-44db-a9e7-7edf3ebca70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.78035569190979\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    cat, item, cten, itens = get_random_sample()\n",
    "    output, loss = train(itens, cten)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f'Loss: {loss}')\n",
    "        print([torch.argmax(output).item()] == cten.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "906b28a3-050e-4fcb-a762-e156984f4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cten.float().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecccfdef-818c-477b-af22-a3253d1444db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d6228-0a1f-4757-aabc-8a7df2e73139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87ab1d0e-63ef-461f-924e-ee98a127c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for gg in rnn.parameters():\n",
    "    print(gg.grad.zero_())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd89d6-bbf2-47d8-96b8-672b2eea72e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe0b5a28-3da8-4e4a-840e-6905fe330e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTrainingExample = get_random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdf28110-328a-4927-a89e-28993e9f21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = torch.zeros((1, n_hidden))\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = loss_fn(output, category_tensor.float())\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1784b3d-d2b6-4786-a921-ec6a8422851b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_iters \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     category, line, category_tensor, line_tensor \u001b[38;5;241m=\u001b[39m randomTrainingExample()\n\u001b[0;32m---> 25\u001b[0m     output, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Print ``iter`` number, loss, name and guess\u001b[39;00m\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(category_tensor, line_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(line_tensor\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      9\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m rnn(line_tensor[i], hidden)\n\u001b[0;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Add parameters' gradients to their values, multiplied by learning rate\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:211\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:2689\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2688\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 10000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print ``iter`` number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc1077-3aab-498d-91e6-f0d37930c25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a612fb-9df8-4255-963e-e0a8a5c26c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bf871-bdf9-4941-88e8-2dc1ffbf5031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c7623-6cfa-4ab4-b01d-41bc85605416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2da2a60d-5932-4d72-a52f-c935e10833bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Korean', 'Irish', 'Portuguese', 'Vietnamese', 'Czech'],\n",
       " '_________',\n",
       " {'Korean': ['Ahn', 'Baik'],\n",
       "  'Irish': ['Adam', 'Ahearn'],\n",
       "  'Portuguese': ['Abreu', 'Albuquerque'],\n",
       "  'Vietnamese': ['Nguyen', 'Tron'],\n",
       "  'Czech': ['Abl', 'Adsit'],\n",
       "  'Russian': ['Ababko', 'Abaev'],\n",
       "  'Scottish': ['Smith', 'Brown'],\n",
       "  'German': ['Abbing', 'Abel'],\n",
       "  'Polish': ['Adamczak', 'Adamczyk'],\n",
       "  'Spanish': ['Abana', 'Abano'],\n",
       "  'English': ['Abbas', 'Abbey'],\n",
       "  'French': ['Abel', 'Abraham'],\n",
       "  'Japanese': ['Abe', 'Abukara'],\n",
       "  'Dutch': ['Aalsburg', 'Aalst'],\n",
       "  'Greek': ['Adamidis', 'Adamou'],\n",
       "  'Chinese': ['Ang', 'AuYong'],\n",
       "  'Italian': ['Abandonato', 'Abatangelo'],\n",
       "  'Arabic': ['Khoury', 'Nahas']})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[:5], \"_________\",{k: category_lines[k][:2] for k in category_lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef88b88-7e02-43f3-b9e4-a758d67102df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fed8a420-ddce-4b74-b20e-c711ed34ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLetters = all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bba97ed-a48e-4fca-8ff3-cd45db6d27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLetters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb0c324e-9df4-4c87-a1e9-7bc90ce2eef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numLetters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41553ded-f454-49f6-9411-b8464e56d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_and_hidden_to_new_hidden = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.new_hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        concatted = torch.cat((input_tensor, hidden_tensor), dim=1)\n",
    "        next_hidden = self.input_and_hidden_to_new_hidden(concatted)\n",
    "        output = self.new_hidden_to_output(next_hidden)\n",
    "        # print(output)\n",
    "        # print(output.argmax())\n",
    "        # print(\"--------------\")\n",
    "        # print(nn.Softmax(dim=1)(output))\n",
    "        output = self.softmax(output)\n",
    "        # print(output)\n",
    "        # print(output.argmax())\n",
    "        return output, next_hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7086af87-ff48-4160-af14-cb030c65810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hidden(hidden_size):\n",
    "    return torch.zeros(1, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3d54686-d5f7-4102-a211-4835cf6d10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_hidden(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2503208-0227-470e-b569-5ae1e18d5ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Portuguese',\n",
       " 'Cardozo',\n",
       " tensor([2]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61e8e0d6-a458-4d37-be03-5a546ee18dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label, name, labelTensor, nameTensor = get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c189e83-7c62-42f3-b794-cf7f98f50c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLetters = num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c610e100-c22c-49b6-a540-82f2b9c24a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCats = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3a26210-6eaf-4a97-bcd6-9a14936ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "numHidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dda16279-8d43-4180-839c-2c9c7a304698",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = RNN2(numLetters, numHidden, numCats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8cf9964-b95b-4676-adfc-02bc93c04a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = init_hidden(numHidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14040bbc-6847-430b-b930-44ed0f949f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nameTensor.size()[0]):\n",
    "    output, hidden = rnn2(nameTensor[i], hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a8e9177-e988-4689-9a8a-7fd05a8d0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor([[0.0503, 0.0554, 0.0539, 0.0609, 0.0575, 0.0518, 0.0531, 0.0571, 0.0536,\n",
    "         0.0602, 0.0603, 0.0549, 0.0533, 0.0536, 0.0547, 0.0514, 0.0572, 0.0607]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d7c7fea-5744-4d0d-ad2c-8c0207f359d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fc8416b-0f1e-4c02-8060-9aabcb274fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.log(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78d66677-4297-4e41-90fa-c3f89a71ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0503, 0.0554, 0.0539, 0.0609, 0.0575, 0.0518, 0.0531, 0.0571, 0.0536,\n",
       "         0.0602, 0.0603, 0.0549, 0.0533, 0.0536, 0.0547, 0.0514, 0.0572, 0.0607]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=1)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95d1da7d-7ffb-4f6e-a16f-11ad6b113792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[-2.9898, -2.9681, -2.9604]]),\n",
       "indices=tensor([[ 0, 15,  5]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(3, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df779203-5e5a-4875-91ea-40a9520d890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
       "\n",
       "See :func:`torch.topk`\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.topk??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3f60d96-0fea-46ff-943d-48982d25796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, sampleTensor, labelTensor):\n",
    "    model.train()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    hidden = model.init_hidden()\n",
    "    for i in range(nameTensor.size()[0]):\n",
    "        output, hidden = rnn2(nameTensor[i], hidden)\n",
    "    \n",
    "    loss = loss_fn(output, labelTensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in model.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "    \n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20e39dff-1fe3-4782-898d-a0d15d816ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = RNN2(numLetters, numHidden, numCats)\n",
    "optimizer = torch.optim.SGD(rnn2.parameters(), lr=0.0001)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eae907-6452-45ce-bad9-430f873a975a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14b19d7c-3c03-4fb6-9d3e-64c7ac401219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.87 µs\n",
      "0 Loss: 2.7582786083221436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time\n",
    "for i in range(1):\n",
    "    label, name, labelTensor, nameTensor = get_random_sample()\n",
    "    loss = train(rnn2,optimizer,loss_fn,nameTensor, labelTensor)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i} Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee218c4-7d80-4985-af9c-ba8a2ef97f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "caef4af5-0495-4e1b-a223-b3281cabe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    hidden = rnn2.init_hidden()\n",
    "    label, name, labelTensor, nameTensor = get_random_sample()\n",
    "    for i in range(nameTensor.shape[0]):\n",
    "        output, hidden = rnn2(nameTensor[i], hidden)\n",
    "    print(f\"{output.argmax() == labelTensor} name: {name}; predicted: {categories[output.argmax().item()]}; Actual: {label}\")\n",
    "    return (output.argmax() == labelTensor).float().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45738de1-24a5-4b4d-8e51-2a0ecee7d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "    label, name, labelTensor, nameTensor = get_random_sample()\n",
    "    for i in range(nameTensor.shape[0]):\n",
    "        output, hidden = rnn2(nameTensor[i], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ece58590-e612-4355-bd3b-2d4e7fd67e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.argmax() == labelTensor).float().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e7c8e0d-9964-4464-bad5-22393d9c7935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[output.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "173525f1-0714-403d-9465-dc3044b86d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False]) name: Dao; predicted: Korean; Actual: Vietnamese\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(1):\n",
    "    correct += evaluate()\n",
    "\n",
    "correct / 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880d33f-3a86-401b-8ff3-1b3d72a3b66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33b3f596-7f98-47b8-a060-3d12972312b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2101759970.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [76]\u001b[0;36m\u001b[0m\n\u001b[0;31m    str.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92a89195-31cd-4ef7-afd8-f78063929246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f64a04d8-ba02-4b44-a3d8-3c87279d478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLetters = string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a8f8468-3066-4cfa-9a19-508916b9f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "import unicodedata\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in allLetters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b51873d7-9271-44c3-81cd-6920f2e19c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'l', 'u', 's', 'a', 'r', 's', 'k', 'i']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in unicodedata.normalize('NFD', 'Ślusàrski') if c in allLetters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c159f8c1-68ee-43c8-8a21-9192ed2788ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ślusàrski'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.normalize('NFD', 'Ślusàrski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e4b52c6-73d4-4a99-b11f-3ed896b40f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function unicodedata.category(chr, /)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006c760b-ba79-4d7c-b255-97bd7cf6a8c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mPath\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02-data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "Path('02-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07309eb3-aa17-4c6f-ab15-f5bbed81b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf419f9a-8d7d-4b0d-a407-6ce2ea190702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean.txt',\n",
       " 'Irish.txt',\n",
       " 'Portuguese.txt',\n",
       " 'Vietnamese.txt',\n",
       " 'Czech.txt',\n",
       " 'Russian.txt',\n",
       " 'Scottish.txt',\n",
       " 'German.txt',\n",
       " 'Polish.txt',\n",
       " 'Spanish.txt',\n",
       " 'English.txt',\n",
       " 'French.txt',\n",
       " 'Japanese.txt',\n",
       " 'Dutch.txt',\n",
       " 'Greek.txt',\n",
       " 'Chinese.txt',\n",
       " 'Italian.txt',\n",
       " 'Arabic.txt']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('02-data/names/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f7321fd-776a-443d-81da-09562e5cc71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('02-data/names/Korean.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        print(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3fc09f6-7c2f-48e3-8231-89c52f583faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m511\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open a file for low level IO.  Returns a file descriptor (integer).\n",
       "\n",
       "If dir_fd is not None, it should be a file descriptor open to a directory,\n",
       "  and path should be relative; path will then be relative to that directory.\n",
       "dir_fd may not be implemented on your platform.\n",
       "  If it is unavailable, using it will raise a NotImplementedError.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "177f6db0-29a9-4448-aa25-c9bdc5322a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = []\n",
    "dict = {}\n",
    "path = '02-data/names/'\n",
    "for fname in os.listdir('02-data/names/'):\n",
    "    lang = fname.split('.')[0]\n",
    "    cats.append(lang)\n",
    "    dict[lang] = []\n",
    "    with open(path+fname) as f:\n",
    "        for line in f:\n",
    "            dict[lang].append(unicodeToAscii(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "590d79b2-6630-4ab5-ba7d-b52ec5a9c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ahn', 'Baik', 'Bang', 'Byon', 'Cha']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict['Korean'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9c1cca75-09b0-4839-9671-c70860ee76ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean: 94',\n",
       " 'Irish: 232',\n",
       " 'Portuguese: 74',\n",
       " 'Vietnamese: 73',\n",
       " 'Czech: 519',\n",
       " 'Russian: 9408',\n",
       " 'Scottish: 100',\n",
       " 'German: 724',\n",
       " 'Polish: 139',\n",
       " 'Spanish: 298',\n",
       " 'English: 3668',\n",
       " 'French: 277',\n",
       " 'Japanese: 991',\n",
       " 'Dutch: 297',\n",
       " 'Greek: 203',\n",
       " 'Chinese: 268',\n",
       " 'Italian: 709',\n",
       " 'Arabic: 2000']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{k}: {len(dict[k])}\" for k in dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43a6050e-0794-401e-9eba-7ec0d08697d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.zeros(1, len(allLetters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fed52667-87a5-4a26-990f-48305b870e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sToI(ch):\n",
    "    return allLetters.index(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e4ea0dc4-4a27-4f23-a9e3-2b7777903a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotChar(char):\n",
    "    zeros = torch.zeros(1, len(allLetters))\n",
    "    zeros[0, sToI(char)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6aabd56c-8e90-4b17-a188-26f6ce7ccff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToTensor(string):\n",
    "    return torch.stack([onehotChar(ch) for ch in string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fd0fd-a42c-406f-adfb-c29ceab3e55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7201799b-d6e5-4e4f-8e43-b55a39a792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c57e3474-9484-410a-9c0e-7db9977b9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSample():\n",
    "    cat = random.choice(cats)\n",
    "    name = random.choice(dict[cat])\n",
    "    return name, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4700ea90-a216-4d07-ac8d-08ff9e15dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleAsTensor(sample):\n",
    "    name, cat = sample\n",
    "    name = stringToTensor(name)\n",
    "    cat = torch.tensor([cats.index(cat)])\n",
    "    return name, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325f938-4f14-477a-a936-3ce9e15c541e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26191332-cae0-4d84-ae0a-73ddf14e866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]]]),\n",
       " tensor([11]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleAsTensor(('Pettigrew', 'French'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f9c0e-d700-4a73-8285-ea7e68f95ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923328c-b92a-4457-9f23-249f8e763d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
