{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53acf757-1c62-40e3-a686-6836cbf23f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c7859-9af4-4cd0-8636-046daa573f84",
   "metadata": {},
   "source": [
    "#### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa6f669-a61e-4c4b-83d3-b4a3e0ea514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment if not downloaded previously\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fed39-0fe3-4e8c-a008-82491d3b69f3",
   "metadata": {},
   "source": [
    "#### format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091ca878-da9f-4839-afda-d842c58c0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "all_letters = string.ascii_letters + \" .,;'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d812f13-2aab-4795-8ec8-a9a3dbd1d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "import unicodedata\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ba7727-3a89-48b9-9f79-2118a98e5166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Korean, Irish, Portuguese, Vietnamese, Czech, Russian, Scottish, German, Polish, Spanish, English, French, Japanese, Dutch, Greek, Chinese, Italian, Arabic'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "category_lines = {}\n",
    "categories = []\n",
    "path = '02-data/names/'\n",
    "for fname in os.listdir(path):\n",
    "    lang = fname.split('.')[0]\n",
    "    categories.append(lang)\n",
    "    category_lines[lang] = []\n",
    "    with open(path+fname, 'r') as f:\n",
    "      for line in f:\n",
    "        category_lines[lang].append(unicodeToAscii(line.strip()))\n",
    "', '.join(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae71ef9-40f1-4475-a7be-cfd03062b4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Korean',\n",
       " 'Irish',\n",
       " 'Portuguese',\n",
       " 'Vietnamese',\n",
       " 'Czech',\n",
       " 'Russian',\n",
       " 'Scottish',\n",
       " 'German',\n",
       " 'Polish',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'French',\n",
       " 'Japanese',\n",
       " 'Dutch',\n",
       " 'Greek',\n",
       " 'Chinese',\n",
       " 'Italian',\n",
       " 'Arabic']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be82e438-d2f5-4c55-8e08-3e32366f0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4757710-4537-490d-b3d7-7af06d602860",
   "metadata": {},
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bfe9a2-c3ab-4247-a499-07dff996c9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_letters = len(all_letters);num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de80198b-d3d1-4b67-902d-375cd0aba18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "letterToIndex('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af3020a-5681-4b18-8fad-1e05e8c20455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_one_hot(char):\n",
    "    zeros = torch.zeros(1, num_letters)\n",
    "    zeros[0][letterToIndex(char)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b154a6-b855-49a1-aaa8-c7585228b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_one_hot('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36bc508-3906-4372-9912-e9d5ada20454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_onehot(word):\n",
    "    zeros = torch.zeros(len(word), 1, num_letters)\n",
    "    for i, ch in enumerate(word):\n",
    "        zeros[i][0][letterToIndex(ch)] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901c1154-e81a-422d-977c-f6d24414dfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]),\n",
       " torch.Size([3, 1, 57]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_onehot('nan'), seq_onehot('nan').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7c4c08-5938-4ca9-b592-95ace60404c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "print(seq_onehot('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8017cb4b-1c96-48ad-803a-d9731ebaa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_and_hidden_to_next_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.new_hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden):\n",
    "        next_hidden = self.input_and_hidden_to_next_hidden(torch.cat((input_tensor, hidden), 1))\n",
    "        output = self.new_hidden_to_output(next_hidden)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "\n",
    "        return output, next_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ee6a30-f63d-4988-94f7-97071c7fa28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(num_letters, 50, len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "563f69fa-c2f9-4833-b196-1e67cd61c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.zeros((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "529a273c-1296-4cde-bc77-c48ff340bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18])\n"
     ]
    }
   ],
   "source": [
    "for char in seq_onehot('nan'):\n",
    "    output, hidden = rnn(char, hidden)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "303c4ee6-8e5b-4a1d-ac35-e48d823bf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ed98136-e472-461d-a800-9680001dd69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Spanish', 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoryFromOutput(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc4f55d8-51c2-4a47-86f7-79dc660e21a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 107])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((seq_onehot('nan')[0], hidden), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "020587ec-9056-41df-b6ea-ffe8ab972f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a5927-2c4a-4ac8-9ce8-2313342a47ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a77a09bb-b7e5-4f60-81fa-93e02935511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_sample():\n",
    "    def rand(collection):\n",
    "        rand_int = random.randint(0, len(collection)-1)\n",
    "        return collection[rand_int]\n",
    "    cat = rand(categories)\n",
    "    item = rand(category_lines[cat])\n",
    "    cat_tensor = torch.tensor([categories.index(cat)])\n",
    "    item_tensor = seq_onehot(item)\n",
    "    return cat, item, cat_tensor, item_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b7c2a11-cb28-4b9a-992e-6ce329065662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Greek',\n",
       " 'Alexandropoulos',\n",
       " tensor([14]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2ead14f-5d35-4456-8d68-4fa90e3edc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, item, cten, itens = get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb1a327c-3610-427f-b5a3-2d2da7ca57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in itens:\n",
    "    out, hidden = rnn(ch, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfabf31f-bcb9-4768-8636-936872e4ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.7322, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][torch.argmax(out).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66f93303-7f59-4c05-8571-5a09d6e41c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn(out[0][torch.argmax(out).item()], cten.float()).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8384118-90d2-446c-9f01-2f77af460f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f4d7b-fc04-44e4-abb8-4a94390bb21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca5518-b786-44a1-8a0c-ac651960807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85d51620-e0c7-4681-824a-00c4da573667",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50\n",
    "rnn = RNN(num_letters, n_hidden, len(categories))\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(input_tensor, cat_tensor):\n",
    "    hidden = torch.zeros((1, n_hidden))\n",
    "\n",
    "    for ch in input_tensor:\n",
    "        out, hidden = rnn(ch, hidden)\n",
    "    \n",
    "    loss = loss_fn(out, cat_tensor)\n",
    "    # # hidden.detach_()\n",
    "    # # out.detach_()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96fb45fa-ea4c-44db-a9e7-7edf3ebca70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.934276580810547\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    cat, item, cten, itens = get_random_sample()\n",
    "    output, loss = train(itens, cten)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f'Loss: {loss}')\n",
    "        print([torch.argmax(output).item()] == cten.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "906b28a3-050e-4fcb-a762-e156984f4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cten.float().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecccfdef-818c-477b-af22-a3253d1444db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d6228-0a1f-4757-aabc-8a7df2e73139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ab1d0e-63ef-461f-924e-ee98a127c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for gg in rnn.parameters():\n",
    "    print(gg.grad.zero_())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd89d6-bbf2-47d8-96b8-672b2eea72e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe0b5a28-3da8-4e4a-840e-6905fe330e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTrainingExample = get_random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdf28110-328a-4927-a89e-28993e9f21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = torch.zeros((1, n_hidden))\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = loss_fn(output, category_tensor.float())\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1784b3d-d2b6-4786-a921-ec6a8422851b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_iters \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     category, line, category_tensor, line_tensor \u001b[38;5;241m=\u001b[39m randomTrainingExample()\n\u001b[0;32m---> 25\u001b[0m     output, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     current_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Print ``iter`` number, loss, name and guess\u001b[39;00m\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(category_tensor, line_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(line_tensor\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      9\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m rnn(line_tensor[i], hidden)\n\u001b[0;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Add parameters' gradients to their values, multiplied by learning rate\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:211\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:2689\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2688\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 10000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print ``iter`` number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc1077-3aab-498d-91e6-f0d37930c25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a612fb-9df8-4255-963e-e0a8a5c26c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bf871-bdf9-4941-88e8-2dc1ffbf5031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c7623-6cfa-4ab4-b01d-41bc85605416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2da2a60d-5932-4d72-a52f-c935e10833bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Korean', 'Irish', 'Portuguese', 'Vietnamese', 'Czech'],\n",
       " '_________',\n",
       " {'Korean': ['Ahn', 'Baik'],\n",
       "  'Irish': ['Adam', 'Ahearn'],\n",
       "  'Portuguese': ['Abreu', 'Albuquerque'],\n",
       "  'Vietnamese': ['Nguyen', 'Tron'],\n",
       "  'Czech': ['Abl', 'Adsit'],\n",
       "  'Russian': ['Ababko', 'Abaev'],\n",
       "  'Scottish': ['Smith', 'Brown'],\n",
       "  'German': ['Abbing', 'Abel'],\n",
       "  'Polish': ['Adamczak', 'Adamczyk'],\n",
       "  'Spanish': ['Abana', 'Abano'],\n",
       "  'English': ['Abbas', 'Abbey'],\n",
       "  'French': ['Abel', 'Abraham'],\n",
       "  'Japanese': ['Abe', 'Abukara'],\n",
       "  'Dutch': ['Aalsburg', 'Aalst'],\n",
       "  'Greek': ['Adamidis', 'Adamou'],\n",
       "  'Chinese': ['Ang', 'AuYong'],\n",
       "  'Italian': ['Abandonato', 'Abatangelo'],\n",
       "  'Arabic': ['Khoury', 'Nahas']})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[:5], \"_________\",{k: category_lines[k][:2] for k in category_lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef88b88-7e02-43f3-b9e4-a758d67102df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fed8a420-ddce-4b74-b20e-c711ed34ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLetters = all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bba97ed-a48e-4fca-8ff3-cd45db6d27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLetters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb0c324e-9df4-4c87-a1e9-7bc90ce2eef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numLetters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41553ded-f454-49f6-9411-b8464e56d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_and_hidden_to_new_hidden = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.new_hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        concatted = torch.cat((input_tensor, hidden_tensor), dim=1)\n",
    "        next_hidden = self.input_and_hidden_to_new_hidden(concatted)\n",
    "        output = self.new_hidden_to_output(next_hidden)\n",
    "        # print(output)\n",
    "        # print(output.argmax())\n",
    "        # print(\"--------------\")\n",
    "        # print(nn.Softmax(dim=1)(output))\n",
    "        output = self.softmax(output)\n",
    "        # print(output)\n",
    "        # print(output.argmax())\n",
    "        return output, next_hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7086af87-ff48-4160-af14-cb030c65810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hidden(hidden_size):\n",
    "    return torch.zeros(1, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3d54686-d5f7-4102-a211-4835cf6d10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_hidden(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2503208-0227-470e-b569-5ae1e18d5ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Polish',\n",
       " 'Jaskulski',\n",
       " tensor([8]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61e8e0d6-a458-4d37-be03-5a546ee18dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label, name, labelTensor, nameTensor = get_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c189e83-7c62-42f3-b794-cf7f98f50c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLetters = num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c610e100-c22c-49b6-a540-82f2b9c24a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCats = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3a26210-6eaf-4a97-bcd6-9a14936ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "numHidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dda16279-8d43-4180-839c-2c9c7a304698",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = RNN2(numLetters, numHidden, numCats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8cf9964-b95b-4676-adfc-02bc93c04a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = init_hidden(numHidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14040bbc-6847-430b-b930-44ed0f949f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0107,  0.0112,  0.0289,  0.0029, -0.0863, -0.0592,  0.0808, -0.0493,\n",
      "          0.0191,  0.1192, -0.0926,  0.0505,  0.0171,  0.0919, -0.0454,  0.0426,\n",
      "         -0.0711,  0.0335]], grad_fn=<AddmmBackward0>)\n",
      "tensor(9)\n",
      "--------------\n",
      "tensor([[0.0546, 0.0558, 0.0568, 0.0554, 0.0506, 0.0520, 0.0598, 0.0525, 0.0563,\n",
      "         0.0622, 0.0503, 0.0581, 0.0562, 0.0605, 0.0527, 0.0576, 0.0514, 0.0571]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9075, -2.8856, -2.8679, -2.8939, -2.9831, -2.9560, -2.8160, -2.9461,\n",
      "         -2.8777, -2.7776, -2.9894, -2.8463, -2.8797, -2.8049, -2.9422, -2.8542,\n",
      "         -2.9679, -2.8633]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(9)\n",
      "tensor([[-0.0461, -0.0249,  0.0626, -0.0049, -0.0408, -0.0331,  0.0709, -0.0035,\n",
      "         -0.0154,  0.1084, -0.1216, -0.0200, -0.0833,  0.0923,  0.0044,  0.0204,\n",
      "         -0.0852,  0.0118]], grad_fn=<AddmmBackward0>)\n",
      "tensor(9)\n",
      "--------------\n",
      "tensor([[0.0533, 0.0544, 0.0594, 0.0555, 0.0536, 0.0540, 0.0599, 0.0556, 0.0549,\n",
      "         0.0622, 0.0494, 0.0547, 0.0513, 0.0612, 0.0560, 0.0569, 0.0512, 0.0564]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9323, -2.9111, -2.8236, -2.8911, -2.9269, -2.9193, -2.8153, -2.8896,\n",
      "         -2.9015, -2.7777, -3.0078, -2.9061, -2.9694, -2.7939, -2.8817, -2.8657,\n",
      "         -2.9714, -2.8744]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(9)\n",
      "tensor([[-0.0378,  0.0185,  0.0780, -0.0282, -0.0615, -0.0041,  0.0373,  0.0048,\n",
      "         -0.0476,  0.1313, -0.0733,  0.0264, -0.0495,  0.0902, -0.0159,  0.0225,\n",
      "         -0.0837,  0.0896]], grad_fn=<AddmmBackward0>)\n",
      "tensor(9)\n",
      "--------------\n",
      "tensor([[0.0531, 0.0562, 0.0596, 0.0536, 0.0519, 0.0549, 0.0573, 0.0554, 0.0526,\n",
      "         0.0629, 0.0513, 0.0566, 0.0525, 0.0604, 0.0543, 0.0564, 0.0507, 0.0603]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9354, -2.8791, -2.8196, -2.9258, -2.9591, -2.9017, -2.8603, -2.8928,\n",
      "         -2.9452, -2.7663, -2.9709, -2.8712, -2.9471, -2.8074, -2.9135, -2.8751,\n",
      "         -2.9813, -2.8080]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(9)\n",
      "tensor([[-0.0152,  0.0302,  0.1264, -0.0095, -0.0852, -0.0081,  0.0620,  0.0031,\n",
      "          0.0226,  0.1214, -0.0326,  0.0066, -0.1177,  0.1213,  0.0157,  0.0394,\n",
      "         -0.0504,  0.0314]], grad_fn=<AddmmBackward0>)\n",
      "tensor(2)\n",
      "--------------\n",
      "tensor([[0.0538, 0.0563, 0.0620, 0.0541, 0.0502, 0.0542, 0.0581, 0.0548, 0.0559,\n",
      "         0.0617, 0.0529, 0.0550, 0.0486, 0.0617, 0.0555, 0.0568, 0.0520, 0.0564]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9221, -2.8768, -2.7806, -2.9164, -2.9922, -2.9151, -2.8450, -2.9039,\n",
      "         -2.8844, -2.7856, -2.9396, -2.9004, -3.0246, -2.7857, -2.8913, -2.8676,\n",
      "         -2.9573, -2.8756]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "for i in range(nameTensor.size()[0]):\n",
    "    output, hidden = rnn2(nameTensor[i], hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a8e9177-e988-4689-9a8a-7fd05a8d0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor([[0.0503, 0.0554, 0.0539, 0.0609, 0.0575, 0.0518, 0.0531, 0.0571, 0.0536,\n",
    "         0.0602, 0.0603, 0.0549, 0.0533, 0.0536, 0.0547, 0.0514, 0.0572, 0.0607]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d7c7fea-5744-4d0d-ad2c-8c0207f359d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fc8416b-0f1e-4c02-8060-9aabcb274fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.log(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78d66677-4297-4e41-90fa-c3f89a71ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0503, 0.0554, 0.0539, 0.0609, 0.0575, 0.0518, 0.0531, 0.0571, 0.0536,\n",
       "         0.0602, 0.0603, 0.0549, 0.0533, 0.0536, 0.0547, 0.0514, 0.0572, 0.0607]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=1)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95d1da7d-7ffb-4f6e-a16f-11ad6b113792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[-2.9898, -2.9681, -2.9604]]),\n",
       "indices=tensor([[ 0, 15,  5]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(3, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df779203-5e5a-4875-91ea-40a9520d890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
       "\n",
       "See :func:`torch.topk`\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.topk??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3f60d96-0fea-46ff-943d-48982d25796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, sampleTensor, labelTensor):\n",
    "    model.train()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    hidden = model.init_hidden()\n",
    "    for i in range(nameTensor.size()[0]):\n",
    "        output, hidden = rnn2(nameTensor[i], hidden)\n",
    "    \n",
    "    loss = loss_fn(output, labelTensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in model.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "    \n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "20e39dff-1fe3-4782-898d-a0d15d816ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = RNN2(numLetters, numHidden, numCats)\n",
    "optimizer = torch.optim.SGD(rnn2.parameters(), lr=0.0001)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eae907-6452-45ce-bad9-430f873a975a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14b19d7c-3c03-4fb6-9d3e-64c7ac401219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 11.2 µs\n",
      "tensor([[ 0.0118,  0.0134,  0.0240,  0.0485,  0.0200,  0.0051, -0.0322,  0.0269,\n",
      "          0.0327, -0.0620, -0.0198, -0.0334, -0.0238,  0.0822, -0.0160,  0.0009,\n",
      "         -0.0203, -0.0327]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0561, 0.0562, 0.0568, 0.0582, 0.0566, 0.0557, 0.0537, 0.0570, 0.0573,\n",
      "         0.0521, 0.0544, 0.0536, 0.0541, 0.0602, 0.0546, 0.0555, 0.0543, 0.0537]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.8806, -2.8790, -2.8683, -2.8438, -2.8724, -2.8873, -2.9245, -2.8655,\n",
      "         -2.8596, -2.9544, -2.9122, -2.9258, -2.9162, -2.8102, -2.9084, -2.8915,\n",
      "         -2.9126, -2.9251]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0571, -0.0227, -0.0101,  0.0483,  0.0561,  0.0041, -0.0838,  0.0416,\n",
      "          0.0312, -0.0639,  0.0265, -0.0069, -0.1050,  0.0832,  0.0011,  0.0207,\n",
      "          0.0398, -0.0293]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0525, 0.0543, 0.0550, 0.0583, 0.0588, 0.0558, 0.0511, 0.0579, 0.0573,\n",
      "         0.0521, 0.0571, 0.0552, 0.0500, 0.0604, 0.0556, 0.0567, 0.0578, 0.0540]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9473, -2.9128, -2.9002, -2.8419, -2.8341, -2.8861, -2.9739, -2.8485,\n",
      "         -2.8590, -2.9540, -2.8636, -2.8970, -2.9951, -2.8069, -2.8890, -2.8694,\n",
      "         -2.8504, -2.9195]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0391, -0.0186,  0.0107,  0.0656,  0.0242, -0.0040, -0.0946,  0.1011,\n",
      "          0.0884, -0.0929,  0.0229,  0.0142, -0.0866,  0.0641,  0.0511,  0.0690,\n",
      "          0.0229, -0.0794]], grad_fn=<AddmmBackward0>)\n",
      "tensor(7)\n",
      "--------------\n",
      "tensor([[0.0530, 0.0541, 0.0557, 0.0588, 0.0564, 0.0549, 0.0501, 0.0609, 0.0602,\n",
      "         0.0502, 0.0564, 0.0559, 0.0505, 0.0587, 0.0580, 0.0590, 0.0564, 0.0509]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9380, -2.9175, -2.8882, -2.8332, -2.8746, -2.9028, -2.9935, -2.7978,\n",
      "         -2.8105, -2.9918, -2.8760, -2.8847, -2.9855, -2.8348, -2.8478, -2.8298,\n",
      "         -2.8759, -2.9782]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(7)\n",
      "tensor([[-0.0377, -0.0513, -0.0076,  0.0204,  0.0527, -0.0631, -0.1070,  0.0920,\n",
      "          0.0686, -0.1006,  0.0076, -0.0171, -0.0684,  0.1067,  0.0277, -0.0023,\n",
      "         -0.0070, -0.0884]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0539, 0.0532, 0.0556, 0.0571, 0.0590, 0.0526, 0.0503, 0.0614, 0.0600,\n",
      "         0.0506, 0.0564, 0.0550, 0.0523, 0.0623, 0.0576, 0.0559, 0.0556, 0.0513]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9203, -2.9339, -2.8902, -2.8622, -2.8299, -2.9457, -2.9896, -2.7906,\n",
      "         -2.8139, -2.9832, -2.8750, -2.8997, -2.9510, -2.7759, -2.8549, -2.8849,\n",
      "         -2.8896, -2.9710]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0440,  0.0072, -0.0225,  0.0879,  0.0248, -0.0146, -0.0912,  0.0872,\n",
      "          0.0444, -0.0833,  0.0055,  0.0197, -0.0873,  0.1032,  0.0122, -0.0050,\n",
      "          0.0523, -0.0481]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0529, 0.0557, 0.0541, 0.0604, 0.0567, 0.0545, 0.0505, 0.0604, 0.0578,\n",
      "         0.0509, 0.0556, 0.0564, 0.0507, 0.0613, 0.0560, 0.0550, 0.0583, 0.0527]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9387, -2.8875, -2.9172, -2.8068, -2.8699, -2.9093, -2.9860, -2.8075,\n",
      "         -2.8503, -2.9780, -2.8892, -2.8750, -2.9820, -2.7915, -2.8825, -2.8998,\n",
      "         -2.8424, -2.9428]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "0 Loss: 2.8749866485595703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time\n",
    "for i in range(1):\n",
    "    label, name, labelTensor, nameTensor = get_random_sample()\n",
    "    loss = train(rnn2,optimizer,loss_fn,nameTensor, labelTensor)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i} Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee218c4-7d80-4985-af9c-ba8a2ef97f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "caef4af5-0495-4e1b-a223-b3281cabe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    hidden = rnn2.init_hidden()\n",
    "    label, name, labelTensor, nameTensor = get_random_sample()\n",
    "    for i in range(nameTensor.shape[0]):\n",
    "        output, hidden = rnn2(nameTensor[i], hidden)\n",
    "    print(f\"{output.argmax() == labelTensor} name: {name}; predicted: {categories[output.argmax().item()]}; Actual: {label}\")\n",
    "    return (output.argmax() == labelTensor).float().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45738de1-24a5-4b4d-8e51-2a0ecee7d843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0332,  0.0235,  0.0336,  0.0723,  0.0317,  0.0239, -0.0473,  0.0583,\n",
      "          0.0471, -0.0653,  0.0032, -0.0488, -0.0161,  0.0747,  0.0027,  0.0008,\n",
      "         -0.0235, -0.0435]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0569, 0.0563, 0.0569, 0.0591, 0.0568, 0.0563, 0.0525, 0.0583, 0.0577,\n",
      "         0.0515, 0.0552, 0.0524, 0.0541, 0.0593, 0.0552, 0.0551, 0.0537, 0.0527]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.8670, -2.8766, -2.8665, -2.8278, -2.8685, -2.8762, -2.9475, -2.8418,\n",
      "         -2.8531, -2.9655, -2.8970, -2.9489, -2.9162, -2.8255, -2.8974, -2.8993,\n",
      "         -2.9237, -2.9436]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0471, -0.0367, -0.0073,  0.0595,  0.0418, -0.0072, -0.0861,  0.0371,\n",
      "          0.0389, -0.0786,  0.0285, -0.0009, -0.0887,  0.0916, -0.0261,  0.0017,\n",
      "          0.0279, -0.0221]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0531, 0.0537, 0.0553, 0.0591, 0.0581, 0.0553, 0.0511, 0.0578, 0.0579,\n",
      "         0.0515, 0.0573, 0.0557, 0.0510, 0.0611, 0.0543, 0.0558, 0.0573, 0.0545]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9346, -2.9242, -2.8948, -2.8280, -2.8457, -2.8947, -2.9736, -2.8504,\n",
      "         -2.8486, -2.9661, -2.8590, -2.8884, -2.9762, -2.7959, -2.9136, -2.8858,\n",
      "         -2.8596, -2.9096]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0182, -0.0240, -0.0005,  0.0373,  0.0395, -0.0200, -0.0991,  0.0991,\n",
      "          0.0031, -0.0933,  0.0187, -0.0386, -0.0635,  0.1076,  0.0212,  0.0394,\n",
      "          0.0249, -0.0894]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0546, 0.0543, 0.0556, 0.0578, 0.0579, 0.0545, 0.0504, 0.0614, 0.0558,\n",
      "         0.0507, 0.0567, 0.0535, 0.0522, 0.0620, 0.0568, 0.0579, 0.0570, 0.0509]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9072, -2.9130, -2.8894, -2.8516, -2.8494, -2.9089, -2.9880, -2.7898,\n",
      "         -2.8859, -2.9823, -2.8703, -2.9275, -2.9525, -2.7813, -2.8678, -2.8496,\n",
      "         -2.8641, -2.9784]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0668, -0.0063, -0.0008,  0.0298,  0.0744, -0.0273, -0.0599,  0.0357,\n",
      "          0.0819, -0.0521,  0.0101,  0.0216, -0.0522,  0.1017,  0.0517,  0.0482,\n",
      "          0.0342, -0.0395]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0514, 0.0546, 0.0549, 0.0566, 0.0592, 0.0534, 0.0517, 0.0569, 0.0596,\n",
      "         0.0521, 0.0555, 0.0561, 0.0521, 0.0608, 0.0578, 0.0576, 0.0568, 0.0528]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9687, -2.9081, -2.9027, -2.8720, -2.8275, -2.9292, -2.9618, -2.8662,\n",
      "         -2.8200, -2.9540, -2.8918, -2.8803, -2.9541, -2.8001, -2.8502, -2.8537,\n",
      "         -2.8677, -2.9414]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n"
     ]
    }
   ],
   "source": [
    "    label, name, labelTensor, nameTensor = get_random_sample()\n",
    "    for i in range(nameTensor.shape[0]):\n",
    "        output, hidden = rnn2(nameTensor[i], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ece58590-e612-4355-bd3b-2d4e7fd67e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.argmax() == labelTensor).float().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e7c8e0d-9964-4464-bad5-22393d9c7935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dutch'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[output.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "173525f1-0714-403d-9465-dc3044b86d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0145, -0.0511, -0.0079,  0.0249,  0.0056,  0.0550, -0.0252,  0.0747,\n",
      "          0.0079, -0.0966,  0.0509, -0.0525, -0.0673,  0.0552,  0.0139,  0.0120,\n",
      "          0.0033, -0.0500]], grad_fn=<AddmmBackward0>)\n",
      "tensor(7)\n",
      "--------------\n",
      "tensor([[0.0549, 0.0529, 0.0552, 0.0571, 0.0560, 0.0588, 0.0543, 0.0600, 0.0561,\n",
      "         0.0506, 0.0586, 0.0528, 0.0521, 0.0588, 0.0565, 0.0564, 0.0559, 0.0530]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9025, -2.9391, -2.8959, -2.8631, -2.8824, -2.8330, -2.9132, -2.8133,\n",
      "         -2.8801, -2.9846, -2.8371, -2.9405, -2.9553, -2.8328, -2.8741, -2.8760,\n",
      "         -2.8847, -2.9380]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(7)\n",
      "tensor([[-0.0149, -0.0478, -0.0023, -0.0065,  0.0710,  0.0258, -0.0887,  0.0532,\n",
      "          0.0057, -0.1096,  0.0071, -0.0553, -0.0620,  0.1054, -0.0016,  0.0245,\n",
      "          0.0212, -0.0755]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0551, 0.0533, 0.0558, 0.0556, 0.0601, 0.0574, 0.0512, 0.0590, 0.0563,\n",
      "         0.0501, 0.0563, 0.0529, 0.0526, 0.0622, 0.0558, 0.0573, 0.0571, 0.0519]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.8985, -2.9313, -2.8859, -2.8900, -2.8125, -2.8577, -2.9722, -2.8303,\n",
      "         -2.8779, -2.9932, -2.8764, -2.9388, -2.9455, -2.7782, -2.8851, -2.8591,\n",
      "         -2.8624, -2.9590]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0759,  0.0095, -0.0272,  0.0618,  0.0623, -0.0333, -0.0921,  0.0620,\n",
      "          0.0555, -0.0916, -0.0005,  0.0385, -0.0863,  0.0958,  0.0147, -0.0045,\n",
      "          0.0282, -0.0310]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0514, 0.0560, 0.0540, 0.0590, 0.0591, 0.0537, 0.0506, 0.0591, 0.0587,\n",
      "         0.0507, 0.0555, 0.0577, 0.0509, 0.0611, 0.0563, 0.0553, 0.0571, 0.0538]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9672, -2.8817, -2.9184, -2.8294, -2.8290, -2.9245, -2.9833, -2.8292,\n",
      "         -2.8357, -2.9828, -2.8917, -2.8527, -2.9775, -2.7955, -2.8766, -2.8957,\n",
      "         -2.8631, -2.9223]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0600, -0.0434,  0.0634,  0.0583, -0.0079, -0.0304, -0.0930,  0.0984,\n",
      "          0.0392, -0.1000,  0.0936, -0.0230, -0.0866,  0.0792,  0.0158, -0.0089,\n",
      "          0.0423, -0.0635]], grad_fn=<AddmmBackward0>)\n",
      "tensor(7)\n",
      "--------------\n",
      "tensor([[0.0523, 0.0532, 0.0592, 0.0589, 0.0551, 0.0539, 0.0506, 0.0613, 0.0577,\n",
      "         0.0502, 0.0610, 0.0543, 0.0509, 0.0601, 0.0564, 0.0550, 0.0579, 0.0521]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9510, -2.9343, -2.8275, -2.8326, -2.8988, -2.9213, -2.9840, -2.7926,\n",
      "         -2.8517, -2.9909, -2.7973, -2.9139, -2.9775, -2.8117, -2.8752, -2.8999,\n",
      "         -2.8486, -2.9544]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(7)\n",
      "tensor([[-0.0293,  0.0010,  0.0226,  0.0556,  0.0551, -0.0410, -0.0807,  0.0831,\n",
      "          0.0241, -0.0681,  0.0317,  0.0281, -0.0997,  0.0625,  0.0526,  0.0366,\n",
      "          0.0210, -0.1527]], grad_fn=<AddmmBackward0>)\n",
      "tensor(7)\n",
      "--------------\n",
      "tensor([[0.0538, 0.0555, 0.0567, 0.0586, 0.0586, 0.0532, 0.0511, 0.0602, 0.0568,\n",
      "         0.0518, 0.0572, 0.0570, 0.0502, 0.0590, 0.0584, 0.0575, 0.0566, 0.0476]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9218, -2.8915, -2.8699, -2.8369, -2.8373, -2.9335, -2.9732, -2.8094,\n",
      "         -2.8683, -2.9605, -2.8608, -2.8644, -2.9921, -2.8299, -2.8398, -2.8558,\n",
      "         -2.8714, -3.0451]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(7)\n",
      "tensor([[-0.0351, -0.0351,  0.0135,  0.0273,  0.0534, -0.0322, -0.0879,  0.0842,\n",
      "          0.0727, -0.0641,  0.0064,  0.0214, -0.0860,  0.1047,  0.0287, -0.0165,\n",
      "          0.0186, -0.0844]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0536, 0.0536, 0.0562, 0.0570, 0.0585, 0.0537, 0.0508, 0.0604, 0.0597,\n",
      "         0.0521, 0.0559, 0.0567, 0.0509, 0.0616, 0.0571, 0.0546, 0.0565, 0.0510]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9265, -2.9265, -2.8780, -2.8641, -2.8380, -2.9236, -2.9794, -2.8072,\n",
      "         -2.8188, -2.9555, -2.8850, -2.8700, -2.9775, -2.7867, -2.8627, -2.9080,\n",
      "         -2.8728, -2.9758]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([[-0.0515, -0.0259,  0.0049,  0.0798,  0.0090, -0.0130, -0.0955,  0.0999,\n",
      "          0.0978, -0.0995,  0.0202,  0.0187, -0.0868,  0.0902,  0.0338,  0.0716,\n",
      "          0.0598, -0.0650]], grad_fn=<AddmmBackward0>)\n",
      "tensor(7)\n",
      "--------------\n",
      "tensor([[0.0522, 0.0536, 0.0553, 0.0595, 0.0555, 0.0543, 0.0500, 0.0608, 0.0606,\n",
      "         0.0498, 0.0561, 0.0560, 0.0504, 0.0602, 0.0569, 0.0591, 0.0584, 0.0515]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9523, -2.9266, -2.8959, -2.8210, -2.8918, -2.9137, -2.9962, -2.8009,\n",
      "         -2.8030, -3.0003, -2.8805, -2.8821, -2.9876, -2.8106, -2.8669, -2.8292,\n",
      "         -2.8410, -2.9658]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(7)\n",
      "tensor([[-0.0217,  0.0010, -0.0356,  0.0575,  0.0698, -0.0243, -0.1059,  0.1032,\n",
      "          0.0565, -0.1096, -0.0010,  0.0212, -0.0714,  0.1115, -0.0051, -0.0260,\n",
      "         -0.0017, -0.0548]], grad_fn=<AddmmBackward0>)\n",
      "tensor(13)\n",
      "--------------\n",
      "tensor([[0.0544, 0.0556, 0.0536, 0.0589, 0.0596, 0.0542, 0.0500, 0.0616, 0.0588,\n",
      "         0.0498, 0.0555, 0.0568, 0.0517, 0.0621, 0.0553, 0.0541, 0.0555, 0.0526]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[-2.9120, -2.8893, -2.9259, -2.8328, -2.8205, -2.9146, -2.9962, -2.7871,\n",
      "         -2.8337, -2.9999, -2.8912, -2.8691, -2.9616, -2.7788, -2.8954, -2.9163,\n",
      "         -2.8919, -2.9451]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor(13)\n",
      "tensor([False]) name: Aleshire; predicted: Dutch; Actual: German\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(1):\n",
    "    correct += evaluate()\n",
    "\n",
    "correct / 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880d33f-3a86-401b-8ff3-1b3d72a3b66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3f596-7f98-47b8-a060-3d12972312b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
