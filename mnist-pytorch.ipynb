{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "144b16d1-cc24-4a58-b659-93295f2dd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! [ -e /content ] && pip install -Uqq fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()\n",
    "# #hide\n",
    "# from fastai.vision.all import *\n",
    "# from fastbook import *\n",
    "\n",
    "# matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcb4d75-65eb-41d4-8f46-923989c8e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62762864-4ed2-46ec-97f7-b067b6dd54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a193d16b-d23e-4775-94ba-7fa860f58370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2497a08f-db23-4f3d-8fc5-79f3b0e7a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1234ad68-7220-41f7-997d-2d6248293214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NossonNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024), nn.ReLU(),\n",
    "            nn.Linear(1024, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4705757-e179-4fe6-ab07-b45fedc0f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NossonNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c57795fa-bfe0-48d5-9005-3fdb1432ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NossonNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a2fa9b-161a-46d2-af9d-b5280b3058d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09124047-7a7a-44a2-89fb-83c86d342f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60da7a6-9b5e-4455-a370-b2d68cfc3faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282074ed-9168-44db-82c7-721e259fa0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce87149-163a-4a2d-8236-ec153c9191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d6618d1-2401-40e8-8125-eea925a1e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_dl = DataLoader(training_data, batch_size=(bs))\n",
    "test_dl = DataLoader(test_data, batch_size=(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e282a157-861e-4f05-a05c-02a19c47c856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([64, 1, 28, 28])\n",
      "y shape: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dl:\n",
    "    print(f\"x shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41efd48-53b6-4a77-95a7-4b222ebe3df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64250d46-936f-419c-a279-477fd0eea898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0\n",
      "X shape: torch.Size([64, 1, 28, 28])\n",
      "y shape: torch.Size([64])\n",
      "sample:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEklEQVR4nM2RMS+DURiFn/ullKXC1KWJyVId2ARBQpqUHyBRC0NjsPsPNktj0F9QEgYiIvEDJG3CYhEpMTBI2qEk5+YzfP1uuD6bwVnum3ve877n5IV/jLH8Vmittfao36fyuw8tWUmSahmPPJEUk5oGIOXIixIvNRMyNZewMZXLZQEyLame9pR6jN7iMDx9JFtevZTk+4mwdtuVdD2IN3Z0fRFmQmjvnHY9TeE+jnLs/gJXGWOMCYwxKyUXIC5u5svn78DmdrJRAIYkpwx8svizv2+5536j/UUZYfZMOYCR8pvUWXAeAWiOU+0AS5MhV9XD78pm71Kyz/sD/sqJA0nSXWOvkBAgXXlVvZL9Jd4f4xPJmHJ5CeNkqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 7\n",
    "for batch, (X, y) in enumerate(train_dl):\n",
    "    print(f'batch number: {batch}')\n",
    "    print(f'X shape: {X.shape}')\n",
    "    print(f'y shape: {y.shape}')\n",
    "    print(f'sample:  {y[sample_idx]}')\n",
    "    ToPILImage()(X[sample_idx]).show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f0350ae-b944-4a51-8c35-8f5498a3f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.transforms.transforms.ToPILImage"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07e39acf-410f-4311-9037-d9df431d1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer): # trains a single epoch\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # set model to train mode - needed for accumulating batch norms averages or training augmentations\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model.forward(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e270c7bb-ddda-46a7-997a-c1588c93cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn): # tests a single epoch\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    model.eval() # set to eval mode - use accumulated batch norm avg instead of aggregating, no augmentation (unless applying Test Time Augmentation)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83ec60-13f0-4808-a72f-bd2948cad1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5507c785-747e-412b-9a17-ed1ff7a02e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616d0b6-09ea-4f58-bc48-b114f1fa1a45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be7d48cf-0649-4a72-b5ae-c07d75955c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "-------------\n",
      "loss: 2.309338  [   64/60000]\n",
      "loss: 0.246802  [ 6464/60000]\n",
      "loss: 0.191325  [12864/60000]\n",
      "loss: 0.234399  [19264/60000]\n",
      "loss: 0.135810  [25664/60000]\n",
      "loss: 0.347400  [32064/60000]\n",
      "loss: 0.124021  [38464/60000]\n",
      "loss: 0.245539  [44864/60000]\n",
      "loss: 0.272951  [51264/60000]\n",
      "loss: 0.180539  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.128952 \n",
      "\n",
      "Epoch: 2 \n",
      "-------------\n",
      "loss: 0.084376  [   64/60000]\n",
      "loss: 0.089544  [ 6464/60000]\n",
      "loss: 0.108369  [12864/60000]\n",
      "loss: 0.100593  [19264/60000]\n",
      "loss: 0.051444  [25664/60000]\n",
      "loss: 0.196390  [32064/60000]\n",
      "loss: 0.035104  [38464/60000]\n",
      "loss: 0.113832  [44864/60000]\n",
      "loss: 0.096552  [51264/60000]\n",
      "loss: 0.092924  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.096789 \n",
      "\n",
      "Epoch: 3 \n",
      "-------------\n",
      "loss: 0.080317  [   64/60000]\n",
      "loss: 0.047311  [ 6464/60000]\n",
      "loss: 0.034922  [12864/60000]\n",
      "loss: 0.103515  [19264/60000]\n",
      "loss: 0.048520  [25664/60000]\n",
      "loss: 0.075342  [32064/60000]\n",
      "loss: 0.017659  [38464/60000]\n",
      "loss: 0.112907  [44864/60000]\n",
      "loss: 0.069376  [51264/60000]\n",
      "loss: 0.048075  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.120018 \n",
      "\n",
      "Epoch: 4 \n",
      "-------------\n",
      "loss: 0.043019  [   64/60000]\n",
      "loss: 0.008765  [ 6464/60000]\n",
      "loss: 0.028164  [12864/60000]\n",
      "loss: 0.102646  [19264/60000]\n",
      "loss: 0.014413  [25664/60000]\n",
      "loss: 0.060365  [32064/60000]\n",
      "loss: 0.024360  [38464/60000]\n",
      "loss: 0.022580  [44864/60000]\n",
      "loss: 0.124960  [51264/60000]\n",
      "loss: 0.071228  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.147790 \n",
      "\n",
      "Epoch: 5 \n",
      "-------------\n",
      "loss: 0.048978  [   64/60000]\n",
      "loss: 0.043814  [ 6464/60000]\n",
      "loss: 0.020871  [12864/60000]\n",
      "loss: 0.053994  [19264/60000]\n",
      "loss: 0.006035  [25664/60000]\n",
      "loss: 0.024347  [32064/60000]\n",
      "loss: 0.003346  [38464/60000]\n",
      "loss: 0.072428  [44864/60000]\n",
      "loss: 0.175789  [51264/60000]\n",
      "loss: 0.016489  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.104649 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch: {t+1} \\n-------------\")\n",
    "    train(train_dl, model, loss_fn, optimizer)\n",
    "    test(test_dl, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "646d58ee-7a1b-465b-ace0-90038c5ae15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]),\n",
       " tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][0].shape, training_data[0][0], training_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "189d0965-d157-4bcb-bf53-68ee3f330138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten()(training_data[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c362-4ca2-41c4-a859-d7642b2e6eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eeb04d3-b53c-4e0b-b1bd-5025f8b67ca3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Test Overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d82a5ee-5ab0-4cb7-97e9-733c9de28227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = Subset(training_data, list(range(50)))\n",
    "test_subset = Subset(test_data, list(range(50)))\n",
    "subset_train_loader = DataLoader(train_subset, batch_size=(10))\n",
    "subset_test_loader = DataLoader(test_subset, batch_size=(10))\n",
    "\n",
    "coopppy = NossonNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2a17675-7698-4f06-90fa-79b1fea536bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34578a97-4ff6-4a74-a912-f11bb087ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(coopppy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c505033-eab6-48b2-9c42-b5ad47c6517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "-------------\n",
      "loss: 2.313771  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 2.062582 \n",
      "\n",
      "Epoch: 2 \n",
      "-------------\n",
      "loss: 1.731281  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 1.652768 \n",
      "\n",
      "Epoch: 3 \n",
      "-------------\n",
      "loss: 1.010127  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.230118 \n",
      "\n",
      "Epoch: 4 \n",
      "-------------\n",
      "loss: 0.410080  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.968483 \n",
      "\n",
      "Epoch: 5 \n",
      "-------------\n",
      "loss: 0.131951  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.885906 \n",
      "\n",
      "Epoch: 6 \n",
      "-------------\n",
      "loss: 0.026182  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.980376 \n",
      "\n",
      "Epoch: 7 \n",
      "-------------\n",
      "loss: 0.008225  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.084933 \n",
      "\n",
      "Epoch: 8 \n",
      "-------------\n",
      "loss: 0.003300  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.128579 \n",
      "\n",
      "Epoch: 9 \n",
      "-------------\n",
      "loss: 0.001287  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.145006 \n",
      "\n",
      "Epoch: 10 \n",
      "-------------\n",
      "loss: 0.000633  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.151841 \n",
      "\n",
      "Epoch: 11 \n",
      "-------------\n",
      "loss: 0.000419  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.155563 \n",
      "\n",
      "Epoch: 12 \n",
      "-------------\n",
      "loss: 0.000329  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 1.155768 \n",
      "\n",
      "Epoch: 13 \n",
      "-------------\n",
      "loss: 0.000278  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 1.153752 \n",
      "\n",
      "Epoch: 14 \n",
      "-------------\n",
      "loss: 0.000243  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 1.151045 \n",
      "\n",
      "Epoch: 15 \n",
      "-------------\n",
      "loss: 0.000217  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.148932 \n",
      "\n",
      "Epoch: 16 \n",
      "-------------\n",
      "loss: 0.000197  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.147462 \n",
      "\n",
      "Epoch: 17 \n",
      "-------------\n",
      "loss: 0.000184  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.146559 \n",
      "\n",
      "Epoch: 18 \n",
      "-------------\n",
      "loss: 0.000173  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.145954 \n",
      "\n",
      "Epoch: 19 \n",
      "-------------\n",
      "loss: 0.000165  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.145415 \n",
      "\n",
      "Epoch: 20 \n",
      "-------------\n",
      "loss: 0.000158  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.144847 \n",
      "\n",
      "Epoch: 21 \n",
      "-------------\n",
      "loss: 0.000151  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.144256 \n",
      "\n",
      "Epoch: 22 \n",
      "-------------\n",
      "loss: 0.000145  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.143630 \n",
      "\n",
      "Epoch: 23 \n",
      "-------------\n",
      "loss: 0.000139  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.142981 \n",
      "\n",
      "Epoch: 24 \n",
      "-------------\n",
      "loss: 0.000134  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.142266 \n",
      "\n",
      "Epoch: 25 \n",
      "-------------\n",
      "loss: 0.000128  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.141500 \n",
      "\n",
      "Epoch: 26 \n",
      "-------------\n",
      "loss: 0.000124  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.140723 \n",
      "\n",
      "Epoch: 27 \n",
      "-------------\n",
      "loss: 0.000119  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.139958 \n",
      "\n",
      "Epoch: 28 \n",
      "-------------\n",
      "loss: 0.000115  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.139153 \n",
      "\n",
      "Epoch: 29 \n",
      "-------------\n",
      "loss: 0.000110  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.138377 \n",
      "\n",
      "Epoch: 30 \n",
      "-------------\n",
      "loss: 0.000106  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.137628 \n",
      "\n",
      "Epoch: 31 \n",
      "-------------\n",
      "loss: 0.000102  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.136937 \n",
      "\n",
      "Epoch: 32 \n",
      "-------------\n",
      "loss: 0.000098  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.136301 \n",
      "\n",
      "Epoch: 33 \n",
      "-------------\n",
      "loss: 0.000094  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.135720 \n",
      "\n",
      "Epoch: 34 \n",
      "-------------\n",
      "loss: 0.000091  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.135226 \n",
      "\n",
      "Epoch: 35 \n",
      "-------------\n",
      "loss: 0.000088  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.134761 \n",
      "\n",
      "Epoch: 36 \n",
      "-------------\n",
      "loss: 0.000085  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.134332 \n",
      "\n",
      "Epoch: 37 \n",
      "-------------\n",
      "loss: 0.000082  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133945 \n",
      "\n",
      "Epoch: 38 \n",
      "-------------\n",
      "loss: 0.000079  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133605 \n",
      "\n",
      "Epoch: 39 \n",
      "-------------\n",
      "loss: 0.000077  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133342 \n",
      "\n",
      "Epoch: 40 \n",
      "-------------\n",
      "loss: 0.000074  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133130 \n",
      "\n",
      "Epoch: 41 \n",
      "-------------\n",
      "loss: 0.000072  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132956 \n",
      "\n",
      "Epoch: 42 \n",
      "-------------\n",
      "loss: 0.000070  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132833 \n",
      "\n",
      "Epoch: 43 \n",
      "-------------\n",
      "loss: 0.000068  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132763 \n",
      "\n",
      "Epoch: 44 \n",
      "-------------\n",
      "loss: 0.000066  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132746 \n",
      "\n",
      "Epoch: 45 \n",
      "-------------\n",
      "loss: 0.000064  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132738 \n",
      "\n",
      "Epoch: 46 \n",
      "-------------\n",
      "loss: 0.000062  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132796 \n",
      "\n",
      "Epoch: 47 \n",
      "-------------\n",
      "loss: 0.000061  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.132896 \n",
      "\n",
      "Epoch: 48 \n",
      "-------------\n",
      "loss: 0.000059  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133003 \n",
      "\n",
      "Epoch: 49 \n",
      "-------------\n",
      "loss: 0.000057  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133256 \n",
      "\n",
      "Epoch: 50 \n",
      "-------------\n",
      "loss: 0.000056  [   10/   50]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133487 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs*10):\n",
    "    print(f\"Epoch: {t+1} \\n-------------\")\n",
    "    train(subset_train_loader, coopppy, loss_fn, opt)\n",
    "    test(subset_test_loader, coopppy, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac1e8e-a692-477c-a301-110b7e6ad274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979acec-a56e-4ca2-a3b2-d999e6db3605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d4b4f-7bcc-4e43-8b4c-e65e8c5737d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d97bbe-f231-4e91-94ea-cb2402ca36d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff98e25-17f3-4e66-8569-ed306ad1df67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
